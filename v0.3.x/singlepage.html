

<!DOCTYPE html>
<!--[if IE 8]><html class="no-js lt-ie9" lang="en" > <![endif]-->
<!--[if gt IE 8]><!--> <html class="no-js" lang="en" > <!--<![endif]-->
<head>
  <meta charset="utf-8">
  
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  
  <title>py_stringmatching 0.2 documentation</title>
  

  
  
  
  

  

  
  
    

  

  
  
    <link rel="stylesheet" href="_static/css/theme.css" type="text/css" />
  

  

  
        <link rel="index" title="Index"
              href="genindex.html"/>
        <link rel="search" title="Search" href="search.html"/>
    <link rel="top" title="None" href="singlepage.html#document-index"/> 

  
  <script src="_static/js/modernizr.min.js"></script>

</head>

<body class="wy-body-for-nav" role="document">

   
  <div class="wy-grid-for-nav">

    
    <nav data-toggle="wy-nav-shift" class="wy-nav-side">
      <div class="wy-side-scroll">
        <div class="wy-side-nav-search">
          

          
            <a href="singlepage.html#document-index" class="icon icon-home"> py_stringmatching
          

          
          </a>

          
            
            
              <div class="version">
                0.2
              </div>
            
          

          

          
        </div>

        <div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="main navigation">
          
            
            
            
              <!-- Local TOC -->
              <div class="local-toc"><ul>
<li class="toctree-l1"><a class="reference internal" href="singlepage.html#document-WhatIsNew">What is New?</a></li>
<li class="toctree-l1"><a class="reference internal" href="singlepage.html#document-Installation">Installation</a><ul>
<li class="toctree-l2"><a class="reference internal" href="singlepage.html#requirements">Requirements</a></li>
<li class="toctree-l2"><a class="reference internal" href="singlepage.html#platforms">Platforms</a></li>
<li class="toctree-l2"><a class="reference internal" href="singlepage.html#dependencies">Dependencies</a></li>
<li class="toctree-l2"><a class="reference internal" href="singlepage.html#installing-using-pip">Installing Using pip</a></li>
<li class="toctree-l2"><a class="reference internal" href="singlepage.html#installing-from-source-distribution">Installing from Source Distribution</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="singlepage.html#document-Tutorial">Tutorial</a><ul>
<li class="toctree-l2"><a class="reference internal" href="singlepage.html#selecting-a-similarity-measure">1. Selecting a Similarity Measure</a></li>
<li class="toctree-l2"><a class="reference internal" href="singlepage.html#selecting-a-tokenizer-type">2. Selecting a Tokenizer Type</a></li>
<li class="toctree-l2"><a class="reference internal" href="singlepage.html#creating-a-tokenizer-object-and-using-it-to-tokenize-the-input-strings">3. Creating a Tokenizer Object and Using It to Tokenize the Input Strings</a></li>
<li class="toctree-l2"><a class="reference internal" href="singlepage.html#creating-a-similarity-measure-object-and-using-it-to-compute-a-similarity-score">4. Creating a Similarity Measure Object and Using It to Compute a Similarity Score</a></li>
<li class="toctree-l2"><a class="reference internal" href="singlepage.html#handling-a-large-number-of-string-pairs">Handling a Large Number of String Pairs</a></li>
<li class="toctree-l2"><a class="reference internal" href="singlepage.html#handling-missing-values">Handling Missing Values</a></li>
<li class="toctree-l2"><a class="reference internal" href="singlepage.html#adding-prefix-and-suffix-to-the-input-string-for-qgram-tokenizers">Adding Prefix and Suffix to the Input String for Qgram Tokenizers</a></li>
<li class="toctree-l2"><a class="reference internal" href="singlepage.html#class-hierarchy-for-tokenizers-and-similarity-measures">Class Hierarchy for Tokenizers and Similarity Measures</a></li>
<li class="toctree-l2"><a class="reference internal" href="singlepage.html#references">References</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="singlepage.html#document-Tokenizer">Tokenizers</a><ul>
<li class="toctree-l2"><a class="reference internal" href="singlepage.html#document-AlphabeticTokenizer">Alphabetic Tokenizer</a></li>
<li class="toctree-l2"><a class="reference internal" href="singlepage.html#document-AlphanumericTokenizer">Alphanumeric Tokenizer</a></li>
<li class="toctree-l2"><a class="reference internal" href="singlepage.html#document-DelimiterTokenizer">Delimiter Tokenizer</a></li>
<li class="toctree-l2"><a class="reference internal" href="singlepage.html#document-QgramTokenizer">Qgram Tokenizer</a></li>
<li class="toctree-l2"><a class="reference internal" href="singlepage.html#document-WhitespaceTokenizer">Whitespace Tokenizer</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="singlepage.html#document-SimilarityMeasure">Similarity Measures</a><ul>
<li class="toctree-l2"><a class="reference internal" href="singlepage.html#document-Affine">Affine Gap</a></li>
<li class="toctree-l2"><a class="reference internal" href="singlepage.html#document-BagDistance">Bag Distance</a></li>
<li class="toctree-l2"><a class="reference internal" href="singlepage.html#document-Cosine">Cosine</a></li>
<li class="toctree-l2"><a class="reference internal" href="singlepage.html#document-Dice">Dice</a></li>
<li class="toctree-l2"><a class="reference internal" href="singlepage.html#document-Editex">Editex</a></li>
<li class="toctree-l2"><a class="reference internal" href="singlepage.html#document-GeneralizedJaccard">Generalized Jaccard</a></li>
<li class="toctree-l2"><a class="reference internal" href="singlepage.html#document-HammingDistance">Hamming Distance</a></li>
<li class="toctree-l2"><a class="reference internal" href="singlepage.html#document-Jaccard">Jaccard</a></li>
<li class="toctree-l2"><a class="reference internal" href="singlepage.html#document-Jaro">Jaro</a></li>
<li class="toctree-l2"><a class="reference internal" href="singlepage.html#document-JaroWinkler">Jaro Winkler</a></li>
<li class="toctree-l2"><a class="reference internal" href="singlepage.html#document-Levenshtein">Levenshtein</a></li>
<li class="toctree-l2"><a class="reference internal" href="singlepage.html#document-MongeElkan">Monge Elkan</a></li>
<li class="toctree-l2"><a class="reference internal" href="singlepage.html#document-NeedlemanWunsch">Needleman Wunsch</a></li>
<li class="toctree-l2"><a class="reference internal" href="singlepage.html#document-OverlapCoefficient">Overlap Coefficient</a></li>
<li class="toctree-l2"><a class="reference internal" href="singlepage.html#document-PartialRatio">Partial Ratio</a></li>
<li class="toctree-l2"><a class="reference internal" href="singlepage.html#document-PartialTokenSort">Partial Token Sort</a></li>
<li class="toctree-l2"><a class="reference internal" href="singlepage.html#document-Ratio">Ratio</a></li>
<li class="toctree-l2"><a class="reference internal" href="singlepage.html#document-SmithWaterman">Smith Waterman</a></li>
<li class="toctree-l2"><a class="reference internal" href="singlepage.html#document-SoftTfIdf">Soft TF/IDF</a></li>
<li class="toctree-l2"><a class="reference internal" href="singlepage.html#document-Soundex">Soundex</a></li>
<li class="toctree-l2"><a class="reference internal" href="singlepage.html#document-TfIdf">TF/IDF</a></li>
<li class="toctree-l2"><a class="reference internal" href="singlepage.html#document-TokenSort">Token Sort</a></li>
<li class="toctree-l2"><a class="reference internal" href="singlepage.html#document-TverskyIndex">Tversky Index</a></li>
</ul>
</li>
</ul>
</div>
            
          
        </div>
      </div>
    </nav>

    <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap">

      
      <nav class="wy-nav-top" role="navigation" aria-label="top navigation">
        
          <i data-toggle="wy-nav-top" class="fa fa-bars"></i>
          <a href="singlepage.html#document-index">py_stringmatching</a>
        
      </nav>


      
      <div class="wy-nav-content">
        <div class="rst-content">
          















<div role="navigation" aria-label="breadcrumbs navigation">

  <ul class="wy-breadcrumbs">
    
      <li><a href="singlepage.html#document-index">Docs</a> &raquo;</li>
        
      <li>py_stringmatching 0.2 documentation</li>
    
    
      <li class="wy-breadcrumbs-aside">
        
            
        
      </li>
    
  </ul>

  
  <hr/>
</div>
          <div role="main" class="document" itemscope="itemscope" itemtype="http://schema.org/Article">
           <div itemprop="articleBody">
            
  <div class="section" id="user-manual-for-py-stringmatching">
<h1>User Manual for py_stringmatching<a class="headerlink" href="#user-manual-for-py-stringmatching" title="Permalink to this headline">¶</a></h1>
<p>This document shows the users how to install and use the package. To contribute to or further develop the package, see the <a class="reference external" href="https://sites.google.com/site/anhaidgroup/projects/py_stringmatching">project website</a>, section “For Contributors and Developers”.</p>
</div>
<div class="section" id="contents">
<h1>Contents<a class="headerlink" href="#contents" title="Permalink to this headline">¶</a></h1>
<div class="toctree-wrapper compound">
<span id="document-WhatIsNew"></span><div class="section" id="what-is-new">
<h2>What is New?<a class="headerlink" href="#what-is-new" title="Permalink to this headline">¶</a></h2>
<p>Compared to Version 0.1.0, the following are new:</p>
<blockquote>
<div><ul class="simple">
<li>Qgram tokenizers have been modified to take a flag called “padding”. If this flag is True (the default), then a prefix and a suffix will be added to the input string before tokenizing (see the Tutorial for a reason for this).</li>
<li>Version 0.1.0 does not handle strings in unicode correctly. Specifically, if an input string contains non-ascii characters, a string similarity measure may interpret the string incorrectly and thus compute an incorrect similarity score. In this version we have fixed the string similarity measures. Specifically, we convert the input strings into unicode before computing similarity measures. NOTE: the tokenizers are still not yet unicode-aware.</li>
<li>In Version 0.1.0, the flag “dampen” for TF/IDF similarity measure has the default value of False. In this version we have modified it to have the default value of True, which is the more common value for this flag in practice.</li>
</ul>
</div></blockquote>
</div>
<span id="document-Installation"></span><div class="section" id="installation">
<h2>Installation<a class="headerlink" href="#installation" title="Permalink to this headline">¶</a></h2>
<div class="section" id="requirements">
<h3>Requirements<a class="headerlink" href="#requirements" title="Permalink to this headline">¶</a></h3>
<blockquote>
<div><ul class="simple">
<li>Python 2.7 or Python 3.3+</li>
<li>C or C++ compiler (parts of the package are in Cython for efficiency reasons, and you need C or C++ compiler to compile these parts)</li>
</ul>
</div></blockquote>
</div>
<div class="section" id="platforms">
<h3>Platforms<a class="headerlink" href="#platforms" title="Permalink to this headline">¶</a></h3>
<p>py_stringmatching has been tested on Linux (Ubuntu with Kernel Version 3.13.0-40-generic), OS X (Darwin with Kernel Version 13.4.0), and Windows 8.1.</p>
</div>
<div class="section" id="dependencies">
<h3>Dependencies<a class="headerlink" href="#dependencies" title="Permalink to this headline">¶</a></h3>
<blockquote>
<div><ul class="simple">
<li>numpy 1.7.0 or higher</li>
<li>six</li>
</ul>
</div></blockquote>
<div class="admonition note">
<p class="first admonition-title">Note</p>
<p class="last">The py_stringmatching installer will automatically install the above required packages.</p>
</div>
<p>There are two ways to install py_stringmatching package: using pip or source distribution.</p>
</div>
<div class="section" id="installing-using-pip">
<h3>Installing Using pip<a class="headerlink" href="#installing-using-pip" title="Permalink to this headline">¶</a></h3>
<p>The easiest way to install the package is to use pip, which will retrieve py_stringmatching from PyPI then install it:</p>
<div class="highlight-default"><div class="highlight"><pre><span></span><span class="n">pip</span> <span class="n">install</span> <span class="n">py_stringmatching</span>
</pre></div>
</div>
</div>
<div class="section" id="installing-from-source-distribution">
<h3>Installing from Source Distribution<a class="headerlink" href="#installing-from-source-distribution" title="Permalink to this headline">¶</a></h3>
<p>Step 1: Download the py_stringmatching package from <a class="reference external" href="https://sites.google.com/site/anhaidgroup/projects/py_stringmatching">here</a>.</p>
<p>Step 2: Unzip the package and execute the following command from the package root:</p>
<div class="highlight-default"><div class="highlight"><pre><span></span><span class="n">python</span> <span class="n">setup</span><span class="o">.</span><span class="n">py</span> <span class="n">install</span>
</pre></div>
</div>
<div class="admonition note">
<p class="first admonition-title">Note</p>
<p>The above command will try to install py_stringmatching into the defaul Python directory on your machine. If you do not have installation permission for that directory then you can install the package in your home directory as follows:</p>
<div class="highlight-default"><div class="highlight"><pre><span></span><span class="n">python</span> <span class="n">setup</span><span class="o">.</span><span class="n">py</span> <span class="n">install</span> <span class="o">--</span><span class="n">user</span>
</pre></div>
</div>
<p class="last">For more information see the StackOverflow <a class="reference external" href="http://stackoverflow.com/questions/14179941/how-to-install-python-packages-without-root-privileges">link</a>.</p>
</div>
</div>
</div>
<span id="document-Tutorial"></span><div class="section" id="tutorial">
<h2>Tutorial<a class="headerlink" href="#tutorial" title="Permalink to this headline">¶</a></h2>
<p>Once the package has been installed, you can import the package as follows:</p>
<div class="highlight-ipython"><div class="highlight"><pre><span></span><span class="gp">In [1]: </span><span class="kn">import</span> <span class="nn">py_stringmatching</span> <span class="kn">as</span> <span class="nn">sm</span>
<span class="gt">---------------------------------------------------------------------------</span>
<span class="ne">ImportError</span><span class="g g-Whitespace">                               </span>Traceback (most recent call last)
<span class="nn">&lt;ipython-input-1-171c4a62eee4&gt;</span> in <span class="ni">&lt;module&gt;</span><span class="nt">()</span>
<span class="ne">----&gt; </span><span class="mi">1</span> <span class="kn">import</span> <span class="nn">py_stringmatching</span> <span class="kn">as</span> <span class="nn">sm</span>

<span class="nn">/Users/pradap/Documents/Research/Python-Package/anhaid/scripts/local_tmp/main_repo/py_stringmatching/__init__.py</span> in <span class="ni">&lt;module&gt;</span><span class="nt">()</span>
<span class="g g-Whitespace">     </span><span class="mi">19</span> <span class="kn">from</span> <span class="nn">py_stringmatching.similarity_measure.jaro</span> <span class="kn">import</span> <span class="n">Jaro</span>
<span class="g g-Whitespace">     </span><span class="mi">20</span> <span class="kn">from</span> <span class="nn">py_stringmatching.similarity_measure.jaro_winkler</span> <span class="kn">import</span> <span class="n">JaroWinkler</span>
<span class="ne">---&gt; </span><span class="mi">21</span> <span class="kn">from</span> <span class="nn">py_stringmatching.similarity_measure.levenshtein</span> <span class="kn">import</span> <span class="n">Levenshtein</span>
<span class="g g-Whitespace">     </span><span class="mi">22</span> <span class="kn">from</span> <span class="nn">py_stringmatching.similarity_measure.monge_elkan</span> <span class="kn">import</span> <span class="n">MongeElkan</span>
<span class="g g-Whitespace">     </span><span class="mi">23</span> <span class="kn">from</span> <span class="nn">py_stringmatching.similarity_measure.needleman_wunsch</span> <span class="kn">import</span> <span class="n">NeedlemanWunsch</span>

<span class="nn">/Users/pradap/Documents/Research/Python-Package/anhaid/scripts/local_tmp/main_repo/py_stringmatching/similarity_measure/levenshtein.py</span> in <span class="ni">&lt;module&gt;</span><span class="nt">()</span>
<span class="g g-Whitespace">      </span><span class="mi">1</span> <span class="kn">from</span> <span class="nn">__future__</span> <span class="kn">import</span> <span class="n">division</span>
<span class="g g-Whitespace">      </span><span class="mi">2</span> 
<span class="ne">----&gt; </span><span class="mi">3</span> <span class="kn">from</span> <span class="nn">py_stringmatching</span> <span class="kn">import</span> <span class="n">utils</span>
<span class="g g-Whitespace">      </span><span class="mi">4</span> <span class="kn">from</span> <span class="nn">py_stringmatching.similarity_measure.cython_levenshtein</span> <span class="kn">import</span> <span class="n">levenshtein</span>
<span class="g g-Whitespace">      </span><span class="mi">5</span> <span class="kn">from</span> <span class="nn">py_stringmatching.similarity_measure.sequence_similarity_measure</span> <span class="kn">import</span> \

<span class="ne">ImportError</span>: cannot import name utils
</pre></div>
</div>
<p>Computing a similarity score between two given strings <strong>x</strong> and <strong>y</strong> then typically consists of four steps: (1) selecting a similarity measure type, (2) selecting a tokenizer type, (3) creating a tokenizer object (of the selected type) and using it to tokenize the two given strings <strong>x</strong> and <strong>y</strong>, and (4) creating a similarity measure object (of the selected type) and applying it to the output of the tokenizer to compute a similarity score. We now elaborate on these steps.</p>
<div class="section" id="selecting-a-similarity-measure">
<h3>1. Selecting a Similarity Measure<a class="headerlink" href="#selecting-a-similarity-measure" title="Permalink to this headline">¶</a></h3>
<p>First, you must select a similarity measure. The package py_stringmatching currently provides 23 different measures (with plan to add more). Examples of such measures are Jaccard, Levenshtein, TF/IDF, etc. To understand more about these measures, a good place to start is the string matching chapter of the book “Principles of Data Integration”. (This chapter is available on the package’s homepage.)</p>
<p>A major group of similarity measures treats input strings as <strong>sequences</strong> of characters (e.g., Levenshtein, Smith Waterman). Another group treats input strings as <strong>sets</strong> of tokens (e.g., Jaccard). Yet another group treats input strings as <strong>bags</strong> of tokens (e.g., TF/IDF). A bag of tokens is a collection of tokens such that a token can appear multiple times in the collection (as opposed to a set of tokens, where each token can appear only once).</p>
<dl class="docutils">
<dt>For the currently implemented 23 similarity measures, we have:</dt>
<dd><ul class="first last simple">
<li>sequence-based measures: affine gap, bag distance, editex, Hamming distance, Jaro, Jaro Winkler, Levenshtein, Needleman Wunsch, partial ratio, partial token sort, ratio, Smith Waterman, token sort.</li>
<li>set-based measures: cosine, Dice, Jaccard, overlap coefficient, Tversky Index.</li>
<li>bag-based measures: TF/IDF.</li>
<li>phonetic-based measures: soundex.</li>
</ul>
</dd>
</dl>
<p>(There are also three hybrid similarity measures: Monge Elkan, Soft TF/IDF, and Generalized Jaccard. They are so called because each of these measures uses multiple similarity measures. See their descriptions in this user manual to understand what types of input they expect.)</p>
<p>At this point, you should know if the selected similarity measure treats input strings as sequences, bags, or sets, so that later you can set the parameters of the tokenizing function properly (see Steps 2-3 below).</p>
</div>
<div class="section" id="selecting-a-tokenizer-type">
<h3>2. Selecting a Tokenizer Type<a class="headerlink" href="#selecting-a-tokenizer-type" title="Permalink to this headline">¶</a></h3>
<p>If the above selected similarity measure treats input strings as sequences of characters, then you do not need to tokenize the input strings <strong>x</strong> and <strong>y</strong>, and hence do not have to select a tokenizer type.</p>
<p>Otherwise, you need to select a tokenizer type. The package py_stringmatching currently provides five different tokenizer types: alphabetical tokenizer, alphanumeric tokenizer, delimiter-based tokenizer, qgram tokenizer, and whitespace tokenizer (more tokenizer types can easily be added).</p>
<p>A tokenizer will convert an input string into a set or a bag of tokens, as discussed in Step 3.</p>
</div>
<div class="section" id="creating-a-tokenizer-object-and-using-it-to-tokenize-the-input-strings">
<h3>3. Creating a Tokenizer Object and Using It to Tokenize the Input Strings<a class="headerlink" href="#creating-a-tokenizer-object-and-using-it-to-tokenize-the-input-strings" title="Permalink to this headline">¶</a></h3>
<p>If you have selected a tokenizer type in Step 2, then in Step 3 you create a tokenizer object of that type. If the intended similarity measure (selected in Step 1) treats the input strings as <strong>sets</strong> of tokens, then when creating the tokenizer object, you must set the flag return_set to True. Otherwise this flag defaults to False, and the created tokenizer object will tokenize a string into a <strong>bag</strong> of tokens.</p>
<p>The following examples create tokenizer objects where the flag return_set is not mentioned, thus defaulting to False. So these tokenizer objects will tokenize a string into a bag of tokens.</p>
<div class="highlight-ipython"><div class="highlight"><pre><span></span><span class="go"># create an alphabetical tokenizer that returns a bag of tokens</span>
<span class="gp">In [2]: </span><span class="n">alphabet_tok</span> <span class="o">=</span> <span class="n">sm</span><span class="o">.</span><span class="n">AlphabeticTokenizer</span><span class="p">()</span>
<span class="gt">---------------------------------------------------------------------------</span>
<span class="ne">NameError</span><span class="g g-Whitespace">                                 </span>Traceback (most recent call last)
<span class="nn">&lt;ipython-input-2-e636eea06128&gt;</span> in <span class="ni">&lt;module&gt;</span><span class="nt">()</span>
<span class="ne">----&gt; </span><span class="mi">1</span> <span class="n">alphabet_tok</span> <span class="o">=</span> <span class="n">sm</span><span class="o">.</span><span class="n">AlphabeticTokenizer</span><span class="p">()</span>

<span class="ne">NameError</span>: name &#39;sm&#39; is not defined

<span class="c1"># create an alphanumeric tokenizer</span>
<span class="gp">In [3]: </span><span class="n">alnum_tok</span> <span class="o">=</span> <span class="n">sm</span><span class="o">.</span><span class="n">AlphanumericTokenizer</span><span class="p">()</span>
<span class="gt">---------------------------------------------------------------------------</span>
<span class="ne">NameError</span><span class="g g-Whitespace">                                 </span>Traceback (most recent call last)
<span class="nn">&lt;ipython-input-3-a35d1109bdb0&gt;</span> in <span class="ni">&lt;module&gt;</span><span class="nt">()</span>
<span class="ne">----&gt; </span><span class="mi">1</span> <span class="n">alnum_tok</span> <span class="o">=</span> <span class="n">sm</span><span class="o">.</span><span class="n">AlphanumericTokenizer</span><span class="p">()</span>

<span class="ne">NameError</span>: name &#39;sm&#39; is not defined

<span class="c1"># create a delimiter tokenizer using comma as a delimiter</span>
<span class="gp">In [4]: </span><span class="n">delim_tok</span> <span class="o">=</span> <span class="n">sm</span><span class="o">.</span><span class="n">DelimiterTokenizer</span><span class="p">(</span><span class="n">delim_set</span><span class="o">=</span><span class="p">[</span><span class="s1">&#39;,&#39;</span><span class="p">])</span>
<span class="gt">---------------------------------------------------------------------------</span>
<span class="ne">NameError</span><span class="g g-Whitespace">                                 </span>Traceback (most recent call last)
<span class="nn">&lt;ipython-input-4-742d57ca92fa&gt;</span> in <span class="ni">&lt;module&gt;</span><span class="nt">()</span>
<span class="ne">----&gt; </span><span class="mi">1</span> <span class="n">delim_tok</span> <span class="o">=</span> <span class="n">sm</span><span class="o">.</span><span class="n">DelimiterTokenizer</span><span class="p">(</span><span class="n">delim_set</span><span class="o">=</span><span class="p">[</span><span class="s1">&#39;,&#39;</span><span class="p">])</span>

<span class="ne">NameError</span>: name &#39;sm&#39; is not defined

<span class="c1"># create a qgram tokenizer using q=3</span>
<span class="gp">In [5]: </span><span class="n">qg3_tok</span> <span class="o">=</span> <span class="n">sm</span><span class="o">.</span><span class="n">QgramTokenizer</span><span class="p">(</span><span class="n">qval</span><span class="o">=</span><span class="mi">3</span><span class="p">)</span>
<span class="gt">---------------------------------------------------------------------------</span>
<span class="ne">NameError</span><span class="g g-Whitespace">                                 </span>Traceback (most recent call last)
<span class="nn">&lt;ipython-input-5-046d472d5d82&gt;</span> in <span class="ni">&lt;module&gt;</span><span class="nt">()</span>
<span class="ne">----&gt; </span><span class="mi">1</span> <span class="n">qg3_tok</span> <span class="o">=</span> <span class="n">sm</span><span class="o">.</span><span class="n">QgramTokenizer</span><span class="p">(</span><span class="n">qval</span><span class="o">=</span><span class="mi">3</span><span class="p">)</span>

<span class="ne">NameError</span>: name &#39;sm&#39; is not defined

<span class="c1"># create a whitespace tokenizer</span>
<span class="gp">In [6]: </span><span class="n">ws_tok</span> <span class="o">=</span> <span class="n">sm</span><span class="o">.</span><span class="n">WhitespaceTokenizer</span><span class="p">()</span>
<span class="gt">---------------------------------------------------------------------------</span>
<span class="ne">NameError</span><span class="g g-Whitespace">                                 </span>Traceback (most recent call last)
<span class="nn">&lt;ipython-input-6-40c5e964aa4e&gt;</span> in <span class="ni">&lt;module&gt;</span><span class="nt">()</span>
<span class="ne">----&gt; </span><span class="mi">1</span> <span class="n">ws_tok</span> <span class="o">=</span> <span class="n">sm</span><span class="o">.</span><span class="n">WhitespaceTokenizer</span><span class="p">()</span>

<span class="ne">NameError</span>: name &#39;sm&#39; is not defined
</pre></div>
</div>
<p>Given the string “up up and away”, the tokenizer alphabet_tok (defined above) will convert it into a bag of tokens [‘up’, ‘up’, ‘and’, ‘away’], where the token ‘up’ appears twice.</p>
<p>The following examples create tokenizer objects where the flag return_set is set to True. Thus these tokenizers will tokenize a string into a set of tokens.</p>
<div class="highlight-ipython"><div class="highlight"><pre><span></span><span class="go"># create an alphabetical tokenizer that returns a set of tokens</span>
<span class="gp">In [7]: </span><span class="n">alphabet_tok_set</span> <span class="o">=</span> <span class="n">sm</span><span class="o">.</span><span class="n">AlphabeticTokenizer</span><span class="p">(</span><span class="n">return_set</span><span class="o">=</span><span class="bp">True</span><span class="p">)</span>
<span class="gt">---------------------------------------------------------------------------</span>
<span class="ne">NameError</span><span class="g g-Whitespace">                                 </span>Traceback (most recent call last)
<span class="nn">&lt;ipython-input-7-cf4bc04afbb3&gt;</span> in <span class="ni">&lt;module&gt;</span><span class="nt">()</span>
<span class="ne">----&gt; </span><span class="mi">1</span> <span class="n">alphabet_tok_set</span> <span class="o">=</span> <span class="n">sm</span><span class="o">.</span><span class="n">AlphabeticTokenizer</span><span class="p">(</span><span class="n">return_set</span><span class="o">=</span><span class="bp">True</span><span class="p">)</span>

<span class="ne">NameError</span>: name &#39;sm&#39; is not defined

<span class="c1"># create a whitespace tokenizer that returns a set of tokens</span>
<span class="gp">In [8]: </span><span class="n">ws_tok_set</span> <span class="o">=</span> <span class="n">sm</span><span class="o">.</span><span class="n">WhitespaceTokenizer</span><span class="p">(</span><span class="n">return_set</span><span class="o">=</span><span class="bp">True</span><span class="p">)</span>
<span class="gt">---------------------------------------------------------------------------</span>
<span class="ne">NameError</span><span class="g g-Whitespace">                                 </span>Traceback (most recent call last)
<span class="nn">&lt;ipython-input-8-c3acd9f9314d&gt;</span> in <span class="ni">&lt;module&gt;</span><span class="nt">()</span>
<span class="ne">----&gt; </span><span class="mi">1</span> <span class="n">ws_tok_set</span> <span class="o">=</span> <span class="n">sm</span><span class="o">.</span><span class="n">WhitespaceTokenizer</span><span class="p">(</span><span class="n">return_set</span><span class="o">=</span><span class="bp">True</span><span class="p">)</span>

<span class="ne">NameError</span>: name &#39;sm&#39; is not defined

<span class="c1"># create a qgram tokenizer with q=3 that returns a set of tokens</span>
<span class="gp">In [9]: </span><span class="n">qg3_tok_set</span> <span class="o">=</span> <span class="n">sm</span><span class="o">.</span><span class="n">QgramTokenizer</span><span class="p">(</span><span class="n">qval</span><span class="o">=</span><span class="mi">3</span><span class="p">,</span> <span class="n">return_set</span><span class="o">=</span><span class="bp">True</span><span class="p">)</span>
<span class="gt">---------------------------------------------------------------------------</span>
<span class="ne">NameError</span><span class="g g-Whitespace">                                 </span>Traceback (most recent call last)
<span class="nn">&lt;ipython-input-9-33ee69cbd77d&gt;</span> in <span class="ni">&lt;module&gt;</span><span class="nt">()</span>
<span class="ne">----&gt; </span><span class="mi">1</span> <span class="n">qg3_tok_set</span> <span class="o">=</span> <span class="n">sm</span><span class="o">.</span><span class="n">QgramTokenizer</span><span class="p">(</span><span class="n">qval</span><span class="o">=</span><span class="mi">3</span><span class="p">,</span> <span class="n">return_set</span><span class="o">=</span><span class="bp">True</span><span class="p">)</span>

<span class="ne">NameError</span>: name &#39;sm&#39; is not defined
</pre></div>
</div>
<p>So given the same string “up up and away”, the tokenizer alphabet_tok_set (defined above) will convert it into a set of tokens [‘up’, ‘and’, ‘away’].</p>
<p>All tokenizers have a <strong>tokenize</strong> method which tokenizes a given input string into a set or bag of tokens (depending on whether the flag return_set is True or False), as these examples illustrate:</p>
<div class="highlight-ipython"><div class="highlight"><pre><span></span><span class="gp">In [10]: </span><span class="n">test_string</span> <span class="o">=</span> <span class="s1">&#39; .hello, world!! data, science, is    amazing!!. hello.&#39;</span>

<span class="go"># tokenize into a bag of alphabetical tokens</span>
<span class="gp">In [11]: </span><span class="n">alphabet_tok</span><span class="o">.</span><span class="n">tokenize</span><span class="p">(</span><span class="n">test_string</span><span class="p">)</span>
<span class="gt">---------------------------------------------------------------------------</span>
<span class="ne">NameError</span><span class="g g-Whitespace">                                 </span>Traceback (most recent call last)
<span class="nn">&lt;ipython-input-11-d6f0346864d1&gt;</span> in <span class="ni">&lt;module&gt;</span><span class="nt">()</span>
<span class="ne">----&gt; </span><span class="mi">1</span> <span class="n">alphabet_tok</span><span class="o">.</span><span class="n">tokenize</span><span class="p">(</span><span class="n">test_string</span><span class="p">)</span>

<span class="ne">NameError</span>: name &#39;alphabet_tok&#39; is not defined

<span class="c1"># tokenize into alphabetical tokens (with return_set set to True)</span>
<span class="gp">In [12]: </span><span class="n">alphabet_tok_set</span><span class="o">.</span><span class="n">tokenize</span><span class="p">(</span><span class="n">test_string</span><span class="p">)</span>
<span class="gt">---------------------------------------------------------------------------</span>
<span class="ne">NameError</span><span class="g g-Whitespace">                                 </span>Traceback (most recent call last)
<span class="nn">&lt;ipython-input-12-83b45bcc4272&gt;</span> in <span class="ni">&lt;module&gt;</span><span class="nt">()</span>
<span class="ne">----&gt; </span><span class="mi">1</span> <span class="n">alphabet_tok_set</span><span class="o">.</span><span class="n">tokenize</span><span class="p">(</span><span class="n">test_string</span><span class="p">)</span>

<span class="ne">NameError</span>: name &#39;alphabet_tok_set&#39; is not defined

<span class="c1"># tokenize using comma as the delimiter</span>
<span class="gp">In [13]: </span><span class="n">delim_tok</span><span class="o">.</span><span class="n">tokenize</span><span class="p">(</span><span class="n">test_string</span><span class="p">)</span>
<span class="gt">---------------------------------------------------------------------------</span>
<span class="ne">NameError</span><span class="g g-Whitespace">                                 </span>Traceback (most recent call last)
<span class="nn">&lt;ipython-input-13-e0a7dc29a918&gt;</span> in <span class="ni">&lt;module&gt;</span><span class="nt">()</span>
<span class="ne">----&gt; </span><span class="mi">1</span> <span class="n">delim_tok</span><span class="o">.</span><span class="n">tokenize</span><span class="p">(</span><span class="n">test_string</span><span class="p">)</span>

<span class="ne">NameError</span>: name &#39;delim_tok&#39; is not defined

<span class="c1"># tokenize using whitespace as the delimiter</span>
<span class="gp">In [14]: </span><span class="n">ws_tok</span><span class="o">.</span><span class="n">tokenize</span><span class="p">(</span><span class="n">test_string</span><span class="p">)</span>
<span class="gt">---------------------------------------------------------------------------</span>
<span class="ne">NameError</span><span class="g g-Whitespace">                                 </span>Traceback (most recent call last)
<span class="nn">&lt;ipython-input-14-e6628a297693&gt;</span> in <span class="ni">&lt;module&gt;</span><span class="nt">()</span>
<span class="ne">----&gt; </span><span class="mi">1</span> <span class="n">ws_tok</span><span class="o">.</span><span class="n">tokenize</span><span class="p">(</span><span class="n">test_string</span><span class="p">)</span>

<span class="ne">NameError</span>: name &#39;ws_tok&#39; is not defined
</pre></div>
</div>
<p>Thus, once you have created the tokenizer, you can use the <strong>tokenize</strong> method to tokenize the two input strings <strong>x</strong> and <strong>y</strong> (see more in Step 4 below).</p>
<div class="admonition note">
<p class="first admonition-title">Note</p>
<p class="last">The <strong>tokenize</strong> method returns a <strong>Python list</strong> which represents a set of tokens or a bag of tokens, depending on whether the flag return_set is True or False.</p>
</div>
</div>
<div class="section" id="creating-a-similarity-measure-object-and-using-it-to-compute-a-similarity-score">
<h3>4. Creating a Similarity Measure Object and Using It to Compute a Similarity Score<a class="headerlink" href="#creating-a-similarity-measure-object-and-using-it-to-compute-a-similarity-score" title="Permalink to this headline">¶</a></h3>
<p>Recall that in Step 1 you have selected a similarity measure (e.g., Jaccard, Levenshtein). In this step you start by creating a similarity measure object of the selected type, as illustrated by these examples:</p>
<div class="highlight-ipython"><div class="highlight"><pre><span></span><span class="go"># create a Jaccard similarity measure object</span>
<span class="gp">In [15]: </span><span class="n">jac</span> <span class="o">=</span> <span class="n">sm</span><span class="o">.</span><span class="n">Jaccard</span><span class="p">()</span>
<span class="gt">---------------------------------------------------------------------------</span>
<span class="ne">NameError</span><span class="g g-Whitespace">                                 </span>Traceback (most recent call last)
<span class="nn">&lt;ipython-input-15-17edba11af82&gt;</span> in <span class="ni">&lt;module&gt;</span><span class="nt">()</span>
<span class="ne">----&gt; </span><span class="mi">1</span> <span class="n">jac</span> <span class="o">=</span> <span class="n">sm</span><span class="o">.</span><span class="n">Jaccard</span><span class="p">()</span>

<span class="ne">NameError</span>: name &#39;sm&#39; is not defined

<span class="c1"># create a Levenshtein similarity measure object</span>
<span class="gp">In [16]: </span><span class="n">lev</span> <span class="o">=</span> <span class="n">sm</span><span class="o">.</span><span class="n">Levenshtein</span><span class="p">()</span>
<span class="gt">---------------------------------------------------------------------------</span>
<span class="ne">NameError</span><span class="g g-Whitespace">                                 </span>Traceback (most recent call last)
<span class="nn">&lt;ipython-input-16-06ad66de5bf4&gt;</span> in <span class="ni">&lt;module&gt;</span><span class="nt">()</span>
<span class="ne">----&gt; </span><span class="mi">1</span> <span class="n">lev</span> <span class="o">=</span> <span class="n">sm</span><span class="o">.</span><span class="n">Levenshtein</span><span class="p">()</span>

<span class="ne">NameError</span>: name &#39;sm&#39; is not defined
</pre></div>
</div>
<p>There are two main types of similarity measures.</p>
<ol class="arabic simple">
<li>Those that when given two input strings will compute a true similarity score, which is a number in the range [0,1] such that the higher this number, the more similar the two input strings are.</li>
<li>Those that when given two input strings will compute a distance score, which is a number such that the higher this number, the more <strong>dissimilar</strong> the two input strings are (this number is often not in the range [0,1]). Clearly, Type-2 measures (also known as distance measures), are the reverse of Type-1 measures.</li>
</ol>
<p>For example, Jaccard similarity measure will compute a true similarity score in [0,1] for two input strings. Levenshtein similarity measure, on the other hand, is really a distance measure, which computes the edit distance between the two input strings (see for example Wikipedia or the string matching chapter in the book “Principles of Data Integration”). It is easy to convert a distance score into a true similarity score (again, see examples in the above book chapter).</p>
<p>Given the above, each similarity measure object in py_stringmatching is supplied with two methods: <strong>get_raw_score</strong> and <strong>get_sim_score</strong>. The first method will compute the raw score as defined by that type of similarity measures, be it similarity score or distance score. For example, for Jaccard this method will return a true similarity score, whereas for Levenshtein it will return an edit distance score.</p>
<p>The method <strong>get_sim_score</strong> normalizes the raw score to obtain a true similarity score (a number in [0,1], such that the higher this number the more similar the two strings are). For Jaccard, <strong>get_sim_score</strong> will simply call <strong>get_raw_score</strong>. For Levenshtein, however, <strong>get_sim_score</strong> will normalize the edit distance to return a true similarity score in [0,1].</p>
<p>Here are some examples of using the <strong>get_raw_score</strong> method:</p>
<div class="highlight-ipython"><div class="highlight"><pre><span></span><span class="go"># input strings</span>
<span class="gp">In [17]: </span><span class="n">x</span> <span class="o">=</span> <span class="s1">&#39;string matching package&#39;</span>

<span class="gp">In [18]: </span><span class="n">y</span> <span class="o">=</span> <span class="s1">&#39;string matching library&#39;</span>

<span class="go"># compute Jaccard score over sets of tokens of x and y, tokenized using whitespace</span>
<span class="gp">In [19]: </span><span class="n">jac</span><span class="o">.</span><span class="n">get_raw_score</span><span class="p">(</span><span class="n">ws_tok_set</span><span class="o">.</span><span class="n">tokenize</span><span class="p">(</span><span class="n">x</span><span class="p">),</span> <span class="n">ws_tok_set</span><span class="o">.</span><span class="n">tokenize</span><span class="p">(</span><span class="n">y</span><span class="p">))</span>
<span class="gt">---------------------------------------------------------------------------</span>
<span class="ne">NameError</span><span class="g g-Whitespace">                                 </span>Traceback (most recent call last)
<span class="nn">&lt;ipython-input-19-1d4fcaaf41b0&gt;</span> in <span class="ni">&lt;module&gt;</span><span class="nt">()</span>
<span class="ne">----&gt; </span><span class="mi">1</span> <span class="n">jac</span><span class="o">.</span><span class="n">get_raw_score</span><span class="p">(</span><span class="n">ws_tok_set</span><span class="o">.</span><span class="n">tokenize</span><span class="p">(</span><span class="n">x</span><span class="p">),</span> <span class="n">ws_tok_set</span><span class="o">.</span><span class="n">tokenize</span><span class="p">(</span><span class="n">y</span><span class="p">))</span>

<span class="ne">NameError</span>: name &#39;jac&#39; is not defined

<span class="c1"># compute Jaccard score over sets of tokens of x and y, tokenized into qgrams (with q=3)</span>
<span class="gp">In [20]: </span><span class="n">jac</span><span class="o">.</span><span class="n">get_raw_score</span><span class="p">(</span><span class="n">qg3_tok_set</span><span class="o">.</span><span class="n">tokenize</span><span class="p">(</span><span class="n">x</span><span class="p">),</span> <span class="n">qg3_tok_set</span><span class="o">.</span><span class="n">tokenize</span><span class="p">(</span><span class="n">y</span><span class="p">))</span>
<span class="gt">---------------------------------------------------------------------------</span>
<span class="ne">NameError</span><span class="g g-Whitespace">                                 </span>Traceback (most recent call last)
<span class="nn">&lt;ipython-input-20-cd8608a2299d&gt;</span> in <span class="ni">&lt;module&gt;</span><span class="nt">()</span>
<span class="ne">----&gt; </span><span class="mi">1</span> <span class="n">jac</span><span class="o">.</span><span class="n">get_raw_score</span><span class="p">(</span><span class="n">qg3_tok_set</span><span class="o">.</span><span class="n">tokenize</span><span class="p">(</span><span class="n">x</span><span class="p">),</span> <span class="n">qg3_tok_set</span><span class="o">.</span><span class="n">tokenize</span><span class="p">(</span><span class="n">y</span><span class="p">))</span>

<span class="ne">NameError</span>: name &#39;jac&#39; is not defined

<span class="c1"># compute Levenshtein distance between x and y</span>
<span class="gp">In [21]: </span><span class="n">lev</span><span class="o">.</span><span class="n">get_raw_score</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="p">)</span>
<span class="gt">---------------------------------------------------------------------------</span>
<span class="ne">NameError</span><span class="g g-Whitespace">                                 </span>Traceback (most recent call last)
<span class="nn">&lt;ipython-input-21-fe45c31b74dc&gt;</span> in <span class="ni">&lt;module&gt;</span><span class="nt">()</span>
<span class="ne">----&gt; </span><span class="mi">1</span> <span class="n">lev</span><span class="o">.</span><span class="n">get_raw_score</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="p">)</span>

<span class="ne">NameError</span>: name &#39;lev&#39; is not defined
</pre></div>
</div>
<p>Note that in the above examples, the Jaccard measure treats the input strings as sets of tokens. And indeed, the two tokenizers ws_tok_set and qg3_tok_set as defined earlier would tokenize a string into a set of tokens. The Levenshtein measure, on the other hand, treats the input strings as sequences of characters. Hence when using it we do not have to tokenize the two strings <strong>x</strong> and <strong>y</strong>.</p>
<p>Here are some example of using the <strong>get_sim_score</strong> method:</p>
<div class="highlight-ipython"><div class="highlight"><pre><span></span><span class="go"># get normalized Levenshtein similarity score between x and y</span>
<span class="gp">In [22]: </span><span class="n">lev</span><span class="o">.</span><span class="n">get_sim_score</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="p">)</span>
<span class="gt">---------------------------------------------------------------------------</span>
<span class="ne">NameError</span><span class="g g-Whitespace">                                 </span>Traceback (most recent call last)
<span class="nn">&lt;ipython-input-22-55f5f0e1ed94&gt;</span> in <span class="ni">&lt;module&gt;</span><span class="nt">()</span>
<span class="ne">----&gt; </span><span class="mi">1</span> <span class="n">lev</span><span class="o">.</span><span class="n">get_sim_score</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="p">)</span>

<span class="ne">NameError</span>: name &#39;lev&#39; is not defined

<span class="c1"># get normalized Jaccard similarity score (this is the same as the raw score)</span>
<span class="gp">In [23]: </span><span class="n">jac</span><span class="o">.</span><span class="n">get_sim_score</span><span class="p">(</span><span class="n">ws_tok_set</span><span class="o">.</span><span class="n">tokenize</span><span class="p">(</span><span class="n">x</span><span class="p">),</span> <span class="n">ws_tok_set</span><span class="o">.</span><span class="n">tokenize</span><span class="p">(</span><span class="n">y</span><span class="p">))</span>
<span class="gt">---------------------------------------------------------------------------</span>
<span class="ne">NameError</span><span class="g g-Whitespace">                                 </span>Traceback (most recent call last)
<span class="nn">&lt;ipython-input-23-27455616b324&gt;</span> in <span class="ni">&lt;module&gt;</span><span class="nt">()</span>
<span class="ne">----&gt; </span><span class="mi">1</span> <span class="n">jac</span><span class="o">.</span><span class="n">get_sim_score</span><span class="p">(</span><span class="n">ws_tok_set</span><span class="o">.</span><span class="n">tokenize</span><span class="p">(</span><span class="n">x</span><span class="p">),</span> <span class="n">ws_tok_set</span><span class="o">.</span><span class="n">tokenize</span><span class="p">(</span><span class="n">y</span><span class="p">))</span>

<span class="ne">NameError</span>: name &#39;jac&#39; is not defined
</pre></div>
</div>
<p>So depending on what you want, you can call <strong>get_raw_score</strong> or <strong>get_sim_score</strong>. Note, however, that certain measures such as affine gap, Monge-Elkan, Needleman-Wunsch, Smith-Waterman and Soft TF/IDF do not have a <strong>get_sim_score</strong> method, because there is no straightforward way to normalize the raw scores of these measures into similarity scores in [0,1] (see the Developer Manual for further explanation).</p>
</div>
<div class="section" id="handling-a-large-number-of-string-pairs">
<h3>Handling a Large Number of String Pairs<a class="headerlink" href="#handling-a-large-number-of-string-pairs" title="Permalink to this headline">¶</a></h3>
<p>Steps 1-4 above discuss the case where you want to compute the similarity score of only a single string pair.</p>
<p>There are however cases where you need to compute the similarity scores of many string pairs. For example, given a table A of 10K strings and a table B of 10K strings, you may need to compute the string similarity scores for all 100M string pairs in the Cartesian product of the two tables.</p>
<p>In such cases, you should avoid tokenizing the same string repeatedly, such as calling jac.get_sim_score(ws_tok_set.tokenize(x), ws_tok_set.tokenize(y)) for all pairs (x,y) in the Cartesian product. If you do this, a string x in table A will be tokenized 10K times, since it will appear in 10K pairs. This is clearly unnecessary and very expensive.</p>
<p>Instead, you should tokenize all strings in tables A and B only once, store the output of tokenizing in some Python structure, then call the similarity measure on these structures to compute similarity scores. This will avoid repeated tokenizing of the same strings.</p>
</div>
<div class="section" id="handling-missing-values">
<h3>Handling Missing Values<a class="headerlink" href="#handling-missing-values" title="Permalink to this headline">¶</a></h3>
<p>By “missing values” we mean cases where the values of one or more strings are missing (e.g., represented as None or NaN in Python). For example, given a row “David,,36” in a CSV file, the value of the second cell of this row is missing. So when this file is read into a data frame, the corresponding cell in the data frame will have the value NaN. Note that missing values are different from empty string values, which are represented as “”.</p>
<p>Handling missing values is tricky and application dependent (see the Developer Manual for a detailed discussion). For these reasons, the tokenizers and similarity measures in the package py_stringmatching do not handle missing values. If one of their input arguments is missing, they will stop, raising an error. Put differently, they expect non-missing input arguments.</p>
</div>
<div class="section" id="adding-prefix-and-suffix-to-the-input-string-for-qgram-tokenizers">
<h3>Adding Prefix and Suffix to the Input String for Qgram Tokenizers<a class="headerlink" href="#adding-prefix-and-suffix-to-the-input-string-for-qgram-tokenizers" title="Permalink to this headline">¶</a></h3>
<p>Consider computing a similarity score between two strings “mo” and “moo” using 3gram tokenizing followed by Jaccard scoring. Tokenizing “mo” returns an empty set, because “mo” contains no 3gram. Tokenizing “moo” returns the set {“moo”}. As a result, the Jaccard score between “mo” and “moo” is 0. This is somewhat counterintuitive, because the two strings are similar.</p>
<p>To address such cases, in practice it is common to add a prefix of (q-1) characters (using #) and a suffix of (q-1) characters (using $) to the input string, before generating qgram tokens. For example, “moo” will be padded to be “##moo$$”, before tokenizing. The flag “padding” in qgram tokenizers can be set for this purpose (the default is True, in which case the string will be padded).</p>
</div>
<div class="section" id="class-hierarchy-for-tokenizers-and-similarity-measures">
<h3>Class Hierarchy for Tokenizers and Similarity Measures<a class="headerlink" href="#class-hierarchy-for-tokenizers-and-similarity-measures" title="Permalink to this headline">¶</a></h3>
<p>Version 0.2.0 implements the following class hierarchy for tokenizers:</p>
<dl class="docutils">
<dt>Tokenizer</dt>
<dd><ul class="first last simple">
<li><dl class="first docutils">
<dt>DefinitionTokenizer</dt>
<dd><ul class="first last">
<li>AlphabeticTokenizer</li>
<li>AlphanumericTokenizer</li>
<li>QgramTokenizer</li>
</ul>
</dd>
</dl>
</li>
<li><dl class="first docutils">
<dt>DelimiterTokenizer</dt>
<dd><ul class="first last">
<li>WhitespaceTokenizer</li>
</ul>
</dd>
</dl>
</li>
</ul>
</dd>
</dl>
<p>The version implements the following class hierarchy for similarity measures:</p>
<dl class="docutils">
<dt>SimilarityMeasure</dt>
<dd><ul class="first last simple">
<li><dl class="first docutils">
<dt>SequenceSimilarityMeasure</dt>
<dd><ul class="first last">
<li>Affine</li>
<li>BagDistance</li>
<li>Editex</li>
<li>HammingDistance</li>
<li>Jaro</li>
<li>JaroWinkler</li>
<li>Levenshtein</li>
<li>NeedlemanWunsch</li>
<li>PartialRatio</li>
<li>PartialTokenSort</li>
<li>Ratio</li>
<li>SmithWaterman</li>
<li>TokenSort</li>
</ul>
</dd>
</dl>
</li>
<li><dl class="first docutils">
<dt>TokenSimilarityMeasure</dt>
<dd><ul class="first last">
<li>Cosine</li>
<li>Dice</li>
<li>Jaccard</li>
<li>OverlapCoefficient</li>
<li>TfIdf</li>
<li>TverskyIndex</li>
</ul>
</dd>
</dl>
</li>
<li><dl class="first docutils">
<dt>HybridSimilarityMeasure</dt>
<dd><ul class="first last">
<li>GeneralizedJaccard</li>
<li>MongeElkan</li>
<li>SoftTfIdf</li>
</ul>
</dd>
</dl>
</li>
<li><dl class="first docutils">
<dt>PhoneticSimilarityMeasure</dt>
<dd><ul class="first last">
<li>Soundex</li>
</ul>
</dd>
</dl>
</li>
</ul>
</dd>
</dl>
</div>
<div class="section" id="references">
<h3>References<a class="headerlink" href="#references" title="Permalink to this headline">¶</a></h3>
<p>AnHai Doan, Alon Halevy, Zachary Ives, “Principles of Data Integration”, Morgan Kaufmann, 2012. Chapter 4 “String Matching” (available on the package’s homepage).</p>
</div>
</div>
<span id="document-Tokenizer"></span><div class="section" id="tokenizers">
<h2>Tokenizers<a class="headerlink" href="#tokenizers" title="Permalink to this headline">¶</a></h2>
<div class="toctree-wrapper compound">
<span id="document-AlphabeticTokenizer"></span><div class="section" id="alphabetic-tokenizer">
<h3>Alphabetic Tokenizer<a class="headerlink" href="#alphabetic-tokenizer" title="Permalink to this headline">¶</a></h3>
</div>
<span id="document-AlphanumericTokenizer"></span><div class="section" id="alphanumeric-tokenizer">
<h3>Alphanumeric Tokenizer<a class="headerlink" href="#alphanumeric-tokenizer" title="Permalink to this headline">¶</a></h3>
</div>
<span id="document-DelimiterTokenizer"></span><div class="section" id="delimiter-tokenizer">
<h3>Delimiter Tokenizer<a class="headerlink" href="#delimiter-tokenizer" title="Permalink to this headline">¶</a></h3>
</div>
<span id="document-QgramTokenizer"></span><div class="section" id="qgram-tokenizer">
<h3>Qgram Tokenizer<a class="headerlink" href="#qgram-tokenizer" title="Permalink to this headline">¶</a></h3>
</div>
<span id="document-WhitespaceTokenizer"></span><div class="section" id="whitespace-tokenizer">
<h3>Whitespace Tokenizer<a class="headerlink" href="#whitespace-tokenizer" title="Permalink to this headline">¶</a></h3>
</div>
</div>
</div>
<span id="document-SimilarityMeasure"></span><div class="section" id="similarity-measures">
<h2>Similarity Measures<a class="headerlink" href="#similarity-measures" title="Permalink to this headline">¶</a></h2>
<div class="toctree-wrapper compound">
<span id="document-Affine"></span><div class="section" id="affine-gap">
<h3>Affine Gap<a class="headerlink" href="#affine-gap" title="Permalink to this headline">¶</a></h3>
</div>
<span id="document-BagDistance"></span><div class="section" id="bag-distance">
<h3>Bag Distance<a class="headerlink" href="#bag-distance" title="Permalink to this headline">¶</a></h3>
</div>
<span id="document-Cosine"></span><div class="section" id="cosine">
<h3>Cosine<a class="headerlink" href="#cosine" title="Permalink to this headline">¶</a></h3>
</div>
<span id="document-Dice"></span><div class="section" id="dice">
<h3>Dice<a class="headerlink" href="#dice" title="Permalink to this headline">¶</a></h3>
</div>
<span id="document-Editex"></span><div class="section" id="editex">
<h3>Editex<a class="headerlink" href="#editex" title="Permalink to this headline">¶</a></h3>
</div>
<span id="document-GeneralizedJaccard"></span><div class="section" id="generalized-jaccard">
<h3>Generalized Jaccard<a class="headerlink" href="#generalized-jaccard" title="Permalink to this headline">¶</a></h3>
</div>
<span id="document-HammingDistance"></span><div class="section" id="hamming-distance">
<h3>Hamming Distance<a class="headerlink" href="#hamming-distance" title="Permalink to this headline">¶</a></h3>
</div>
<span id="document-Jaccard"></span><div class="section" id="jaccard">
<h3>Jaccard<a class="headerlink" href="#jaccard" title="Permalink to this headline">¶</a></h3>
</div>
<span id="document-Jaro"></span><div class="section" id="jaro">
<h3>Jaro<a class="headerlink" href="#jaro" title="Permalink to this headline">¶</a></h3>
</div>
<span id="document-JaroWinkler"></span><div class="section" id="jaro-winkler">
<h3>Jaro Winkler<a class="headerlink" href="#jaro-winkler" title="Permalink to this headline">¶</a></h3>
</div>
<span id="document-Levenshtein"></span><div class="section" id="levenshtein">
<h3>Levenshtein<a class="headerlink" href="#levenshtein" title="Permalink to this headline">¶</a></h3>
</div>
<span id="document-MongeElkan"></span><div class="section" id="monge-elkan">
<h3>Monge Elkan<a class="headerlink" href="#monge-elkan" title="Permalink to this headline">¶</a></h3>
</div>
<span id="document-NeedlemanWunsch"></span><div class="section" id="needleman-wunsch">
<h3>Needleman Wunsch<a class="headerlink" href="#needleman-wunsch" title="Permalink to this headline">¶</a></h3>
</div>
<span id="document-OverlapCoefficient"></span><div class="section" id="overlap-coefficient">
<h3>Overlap Coefficient<a class="headerlink" href="#overlap-coefficient" title="Permalink to this headline">¶</a></h3>
</div>
<span id="document-PartialRatio"></span><div class="section" id="partial-ratio">
<h3>Partial Ratio<a class="headerlink" href="#partial-ratio" title="Permalink to this headline">¶</a></h3>
</div>
<span id="document-PartialTokenSort"></span><div class="section" id="partial-token-sort">
<h3>Partial Token Sort<a class="headerlink" href="#partial-token-sort" title="Permalink to this headline">¶</a></h3>
</div>
<span id="document-Ratio"></span><div class="section" id="ratio">
<h3>Ratio<a class="headerlink" href="#ratio" title="Permalink to this headline">¶</a></h3>
</div>
<span id="document-SmithWaterman"></span><div class="section" id="smith-waterman">
<h3>Smith Waterman<a class="headerlink" href="#smith-waterman" title="Permalink to this headline">¶</a></h3>
</div>
<span id="document-SoftTfIdf"></span><div class="section" id="soft-tf-idf">
<h3>Soft TF/IDF<a class="headerlink" href="#soft-tf-idf" title="Permalink to this headline">¶</a></h3>
</div>
<span id="document-Soundex"></span><div class="section" id="soundex">
<h3>Soundex<a class="headerlink" href="#soundex" title="Permalink to this headline">¶</a></h3>
</div>
<span id="document-TfIdf"></span><div class="section" id="tf-idf">
<h3>TF/IDF<a class="headerlink" href="#tf-idf" title="Permalink to this headline">¶</a></h3>
</div>
<span id="document-TokenSort"></span><div class="section" id="token-sort">
<h3>Token Sort<a class="headerlink" href="#token-sort" title="Permalink to this headline">¶</a></h3>
</div>
<span id="document-TverskyIndex"></span><div class="section" id="tversky-index">
<h3>Tversky Index<a class="headerlink" href="#tversky-index" title="Permalink to this headline">¶</a></h3>
</div>
</div>
</div>
</div>
</div>
<div class="section" id="indices-and-tables">
<h1>Indices and tables<a class="headerlink" href="#indices-and-tables" title="Permalink to this headline">¶</a></h1>
<ul class="simple">
<li><a class="reference internal" href="genindex.html"><span class="std std-ref">Index</span></a></li>
<li><a class="reference internal" href="py-modindex.html"><span class="std std-ref">Module Index</span></a></li>
<li><a class="reference internal" href="search.html"><span class="std std-ref">Search Page</span></a></li>
</ul>
</div>


           </div>
           <div class="articleComments">
            
           </div>
          </div>
          <footer>
  

  <hr/>

  <div role="contentinfo">
    <p>
        &copy; Copyright 2016, py_stringmatching Team.

    </p>
  </div>
  Built with <a href="http://sphinx-doc.org/">Sphinx</a> using a <a href="https://github.com/snide/sphinx_rtd_theme">theme</a> provided by <a href="https://readthedocs.org">Read the Docs</a>. 

</footer>

        </div>
      </div>

    </section>

  </div>
  


  

    <script type="text/javascript">
        var DOCUMENTATION_OPTIONS = {
            URL_ROOT:'./',
            VERSION:'0.2',
            COLLAPSE_INDEX:false,
            FILE_SUFFIX:'.html',
            HAS_SOURCE:  true,
            SOURCELINK_SUFFIX: '.txt'
        };
    </script>
      <script type="text/javascript" src="_static/jquery.js"></script>
      <script type="text/javascript" src="_static/underscore.js"></script>
      <script type="text/javascript" src="_static/doctools.js"></script>
      <script type="text/javascript" src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.0/MathJax.js?config=TeX-AMS-MML_HTMLorMML"></script>

  

  
  
    <script type="text/javascript" src="_static/js/theme.js"></script>
  

  
  
  <script type="text/javascript">
      jQuery(function () {
          SphinxRtdTheme.StickyNav.enable();
      });
  </script>
   

</body>
</html>
